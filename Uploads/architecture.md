# AI Companion App for macOS â€” Architecture Overview

## Overview
This architecture document defines the complete technical blueprint for building a full-featured macOS AI Companion using:
- **Frontend**: Next.js (React-based framework)
- **Backend Services**: Supabase (for DB + Auth), Serverless API layer
- **AI Providers**: OpenAI GPT-4o, Claude.AI, Google Gemini 2.5 Flash
- **Features**:
  - Multimodal Input/Output (text & voice)
  - Multi-provider AI routing
  - Knowledge base from documents (PDF, PPT, Excel, etc.)
  - Real-time and asynchronous data processing

---

## ðŸ” Folder Structure

```bash
ai-companion/
â”œâ”€â”€ app/                       # Next.js app routes
â”‚   â”œâ”€â”€ page.tsx              # Main UI (chat interface)
â”‚   â”œâ”€â”€ settings/             # User settings
â”‚   â”œâ”€â”€ upload/               # Document upload logic
â”‚   â””â”€â”€ api/                  # Custom serverless API endpoints
â”œâ”€â”€ components/               # Reusable React components
â”‚   â”œâ”€â”€ ChatWindow.tsx
â”‚   â”œâ”€â”€ VoiceInput.tsx
â”‚   â”œâ”€â”€ VoiceOutput.tsx
â”‚   â””â”€â”€ DocumentViewer.tsx
â”œâ”€â”€ lib/                      # Utility libraries
â”‚   â”œâ”€â”€ aiRouter.ts           # Routes to GPT/Claude/Gemini based on criteria
â”‚   â”œâ”€â”€ knowledgeGraph.ts     # Interface with the vector DB
â”‚   â”œâ”€â”€ documentParser.ts     # Extracts content from PDF, Excel, etc.
â”‚   â””â”€â”€ voiceUtils.ts         # Voice processing helpers
â”œâ”€â”€ hooks/                    # Custom React hooks
â”‚   â”œâ”€â”€ useSpeechToText.ts
â”‚   â””â”€â”€ useTextToSpeech.ts
â”œâ”€â”€ styles/                   # Tailwind or custom CSS
â”œâ”€â”€ supabase/                 # Supabase client and config
â”‚   â”œâ”€â”€ client.ts
â”‚   â””â”€â”€ auth.ts
â”œâ”€â”€ types/                    # TypeScript types
â”œâ”€â”€ public/                   # Static assets
â””â”€â”€ .env                      # API keys & secrets
```

---

## ðŸ§  Feature Breakdown

### 1. Multimodal Input
- **Text**: From ChatWindow
- **Voice**: Via `VoiceInput.tsx` and `useSpeechToText.ts`
- **Tech**: `Web Speech API` (browser) or native macOS input

### 2. Multimodal Output
- **Text**: Rendered in UI (ChatWindow)
- **Voice**: `VoiceOutput.tsx` using `useTextToSpeech.ts`
- **Switch**: UI toggle to switch between text/voice response

### 3. Knowledge Graph / DB
- **Supabase**:
  - Auth (email, social)
  - Postgres DB for metadata
- **Vector DB (e.g., Weaviate or pgvector)**:
  - Store embeddings from documents
- **`knowledgeGraph.ts`** handles querying & updates

### 4. Document Processing
- `upload/` route handles uploads
- `documentParser.ts` extracts text from:
  - PDF: pdf-parse
  - PPTX: pptx2json / libreoffice
  - Excel: sheetjs
- Parsed content converted to embeddings â†’ stored in vector DB

### 5. Multi-AI Integration
- `aiRouter.ts` handles routing requests to:
  - **OpenAI** (via GPT-4o)
  - **Claude.ai** (Anthropic API)
  - **Gemini Flash** (Google PaLM/Gemini API)
- Criteria-based routing:
  - Model availability
  - Task type (vision, summarization, chat)
  - User preference

---

## âš™ï¸ Services & State Management

### State
- **Client-side state**: `useState`, `useReducer`, or `zustand` for UI/UX
- **Server state**:
  - Supabase for persistent storage (user sessions, history)
  - LocalStorage or IndexedDB for temporary client caching

### API Services
- All calls to AI providers via `/api/aiRouter.ts`
- Supabase REST/GraphQL endpoints via client SDK
- Document uploads â†’ `/api/process-doc.ts`
- Authentication â†’ `supabase/auth.ts`

---

## ðŸ” Authentication
- **Supabase Auth** with:
  - Email/Password
  - OAuth (Google, Apple)
- Session tokens managed via cookies or JWTs
- `getUser()` middleware in API endpoints

---

## ðŸ“¡ External API Integration
- **OpenAI GPT-4o**: `/v1/chat/completions`
- **Claude AI**: `https://api.anthropic.com/v1/complete`
- **Google Gemini**: `https://generativelanguage.googleapis.com/...`

All API keys are stored securely in `.env`

---

## ðŸ”„ Data Flow Example

```mermaid
graph TD
User -->|Speaks| VoiceInput -->|Transcribed| ChatWindow
ChatWindow --> aiRouter
aiRouter -->|Summarization| Claude
aiRouter -->|Vision| Gemini
aiRouter -->|Chat| OpenAI
aiRouter --> ChatWindow
ChatWindow --> VoiceOutput
```

---

## ðŸ›  Development Notes
- Use Vercel for deployment of Next.js
- Use Supabase hosted Postgres with `pgvector` extension
- Build audio pipelines using `ffmpeg`, `Web Audio API`, `whisper.js`
- Schedule daily sync for knowledge base updates via CRON

---

## ðŸ§ª Testing
- Unit tests: `Jest`
- Integration: `Playwright`
- Linting: `ESLint + Prettier`

---

## âœ… Next Steps
- [ ] Set up Supabase project & vector DB
- [ ] Configure API keys
- [ ] Build basic ChatWindow with routing
- [ ] Implement voice input/output components
- [ ] Integrate document parser + upload UI